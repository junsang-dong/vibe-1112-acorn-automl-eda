import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score
import xgboost as xgb
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AutoML ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

class DataAnalyzer:
    def __init__(self):
        self.df = None
        self.numeric_cols = []
        self.categorical_cols = []
        self.target_col = None
        self.models = {}
        self.scaler = StandardScaler()
        self.label_encoders = {}
        
    def load_data(self, uploaded_file):
        """CSV íŒŒì¼ ë¡œë“œ ë° ê¸°ë³¸ ì „ì²˜ë¦¬"""
        try:
            self.df = pd.read_csv(uploaded_file)
            
            # 100ê°œ ìƒ˜í”Œë§
            if len(self.df) > 100:
                self.df = self.df.sample(n=100, random_state=42).reset_index(drop=True)
            
            # ê¸°ë³¸ ì „ì²˜ë¦¬
            self.df = self.df.dropna()
            
            # ì»¬ëŸ¼ íƒ€ì… ë¶„ë¥˜
            self.numeric_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()
            self.categorical_cols = self.df.select_dtypes(include=['object', 'bool']).columns.tolist()
            
            # íƒ€ê²Ÿ ë³€ìˆ˜ ìë™ ê°ì§€
            target_candidates = ['Churn', 'Target', 'Label', 'Class', 'churn', 'target', 'label', 'class']
            for col in target_candidates:
                if col in self.df.columns:
                    self.target_col = col
                    break
            
            # íƒ€ê²Ÿ ë³€ìˆ˜ê°€ ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ ì»¬ëŸ¼ì„ íƒ€ê²Ÿìœ¼ë¡œ ì‚¬ìš©
            if self.target_col is None:
                self.target_col = self.df.columns[-1]
            
            return True
        except Exception as e:
            st.error(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
            return False
    
    def preprocess_data(self):
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        try:
            # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
            for col in self.categorical_cols:
                if col != self.target_col:
                    le = LabelEncoder()
                    self.df[col] = le.fit_transform(self.df[col].astype(str))
                    self.label_encoders[col] = le
            
            # íƒ€ê²Ÿ ë³€ìˆ˜ ì¸ì½”ë”©
            if self.df[self.target_col].dtype == 'object':
                le_target = LabelEncoder()
                self.df[self.target_col] = le_target.fit_transform(self.df[self.target_col])
                self.label_encoders[self.target_col] = le_target
            
            return True
        except Exception as e:
            st.error(f"ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return False
    
    def get_basic_stats(self):
        """ê¸°ë³¸ í†µê³„ ì •ë³´"""
        stats = {
            'shape': self.df.shape,
            'columns': list(self.df.columns),
            'numeric_columns': self.numeric_cols,
            'categorical_columns': self.categorical_cols,
            'target_column': self.target_col,
            'missing_values': self.df.isnull().sum().to_dict(),
            'target_distribution': self.df[self.target_col].value_counts().to_dict()
        }
        return stats
    
    def train_models(self):
        """ëª¨ë¸ í•™ìŠµ"""
        try:
            # í”¼ì²˜ì™€ íƒ€ê²Ÿ ë¶„ë¦¬
            X = self.df.drop(columns=[self.target_col])
            y = self.df[self.target_col]
            
            # ë°ì´í„° ë¶„í• 
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
            
            # ìŠ¤ì¼€ì¼ë§
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_test_scaled = self.scaler.transform(X_test)
            
            # ëª¨ë¸ ì •ì˜
            models = {
                'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=5),
                'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, max_depth=5),
                'XGBoost': xgb.XGBClassifier(random_state=42, max_depth=3, n_estimators=100)
            }
            
            results = {}
            
            for name, model in models.items():
                # ëª¨ë¸ í•™ìŠµ
                if name == 'XGBoost':
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                    y_pred_proba = model.predict_proba(X_test)[:, 1] if len(np.unique(y)) == 2 else None
                else:
                    model.fit(X_train_scaled, y_train)
                    y_pred = model.predict(X_test_scaled)
                    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1] if len(np.unique(y)) == 2 else None
                
                # ì„±ëŠ¥ í‰ê°€
                accuracy = accuracy_score(y_test, y_pred)
                
                # êµì°¨ ê²€ì¦
                if name == 'XGBoost':
                    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
                else:
                    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')
                
                results[name] = {
                    'accuracy': float(accuracy),
                    'cv_mean': float(cv_scores.mean()),
                    'cv_std': float(cv_scores.std()),
                    'feature_importance': None
                }
                
                # í”¼ì²˜ ì¤‘ìš”ë„
                if hasattr(model, 'feature_importances_'):
                    feature_importance = {k: float(v) for k, v in zip(X.columns, model.feature_importances_)}
                    results[name]['feature_importance'] = feature_importance
                
                # AUC
                if y_pred_proba is not None and len(np.unique(y)) == 2:
                    try:
                        auc = roc_auc_score(y_test, y_pred_proba)
                        results[name]['auc'] = float(auc)
                    except:
                        pass
                
                self.models[name] = model
            
            return results
            
        except Exception as e:
            st.error(f"ëª¨ë¸ í•™ìŠµ ì˜¤ë¥˜: {e}")
            return {}

def main():
    st.title("ğŸ“Š AutoML ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    st.markdown("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ë°ì´í„° ë¶„ì„ê³¼ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
    
    # ì‚¬ì´ë“œë°”
    st.sidebar.title("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_file = st.sidebar.file_uploader(
        "CSV íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
        type=['csv'],
        help="ìµœëŒ€ 16MBê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
    )
    
    if uploaded_file is not None:
        # ë°ì´í„° ë¡œë“œ
        analyzer = DataAnalyzer()
        
        with st.spinner("ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ë¶„ì„ ì¤‘..."):
            if analyzer.load_data(uploaded_file):
                if analyzer.preprocess_data():
                    st.success("âœ… ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì™„ë£Œ!")
                    
                    # ê¸°ë³¸ í†µê³„
                    stats = analyzer.get_basic_stats()
                    
                    # ë©”ì¸ ëŒ€ì‹œë³´ë“œ
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("ì´ í–‰ ìˆ˜", f"{stats['shape'][0]:,}")
                    with col2:
                        st.metric("ì´ ì—´ ìˆ˜", stats['shape'][1])
                    with col3:
                        st.metric("ìˆ˜ì¹˜í˜• ë³€ìˆ˜", len(stats['numeric_columns']))
                    with col4:
                        st.metric("ë²”ì£¼í˜• ë³€ìˆ˜", len(stats['categorical_columns']))
                    
                    # íƒ€ê²Ÿ ë¶„í¬
                    st.subheader("ğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬")
                    target_dist = stats['target_distribution']
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # ë§‰ëŒ€ ê·¸ë˜í”„
                        fig, ax = plt.subplots(figsize=(8, 6))
                        bars = ax.bar(target_dist.keys(), target_dist.values(), 
                                    color=['#2ecc71', '#e74c3c'])
                        ax.set_title('íƒ€ê²Ÿ ë¶„í¬ (ê±´ìˆ˜)', fontweight='bold')
                        ax.set_xlabel('íƒ€ê²Ÿ ê°’')
                        ax.set_ylabel('ë¹ˆë„')
                        
                        # ê°’ í‘œì‹œ
                        for bar, value in zip(bars, target_dist.values()):
                            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                                   str(value), ha='center', fontweight='bold')
                        
                        st.pyplot(fig)
                    
                    with col2:
                        # íŒŒì´ ì°¨íŠ¸
                        fig, ax = plt.subplots(figsize=(8, 6))
                        colors = ['#2ecc71', '#e74c3c']
                        wedges, texts, autotexts = ax.pie(target_dist.values(), 
                                                        labels=target_dist.keys(), 
                                                        autopct='%1.1f%%',
                                                        colors=colors, startangle=90)
                        ax.set_title('íƒ€ê²Ÿ ë¶„í¬ (ë¹„ìœ¨)', fontweight='bold')
                        st.pyplot(fig)
                    
                    # ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
                    if len(stats['numeric_columns']) > 0:
                        st.subheader("ğŸ”¥ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ")
                        
                        corr_matrix = analyzer.df[stats['numeric_columns'] + [analyzer.target_col]].corr()
                        
                        fig, ax = plt.subplots(figsize=(12, 10))
                        sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='RdYlBu_r',
                                   center=0, square=True, linewidths=0.5, ax=ax)
                        ax.set_title('ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ', fontsize=16, fontweight='bold')
                        st.pyplot(fig)
                    
                    # ëª¨ë¸ í•™ìŠµ
                    st.subheader("ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ")
                    
                    with st.spinner("ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        model_results = analyzer.train_models()
                    
                    if model_results:
                        st.success("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
                        
                        # ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
                        st.subheader("ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
                        
                        # ì„±ëŠ¥ í…Œì´ë¸”
                        performance_data = []
                        for model_name, result in model_results.items():
                            performance_data.append({
                                'ëª¨ë¸': model_name,
                                'ì •í™•ë„': f"{result['accuracy']*100:.2f}%",
                                'êµì°¨ê²€ì¦ í‰ê· ': f"{result['cv_mean']*100:.2f}%",
                                'êµì°¨ê²€ì¦ í‘œì¤€í¸ì°¨': f"{result['cv_std']*100:.2f}%",
                                'AUC': f"{result.get('auc', 'N/A'):.3f}" if result.get('auc') else 'N/A'
                            })
                        
                        performance_df = pd.DataFrame(performance_data)
                        st.dataframe(performance_df, use_container_width=True)
                        
                        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì°¾ê¸°
                        best_model = max(model_results.keys(), 
                                       key=lambda x: model_results[x]['accuracy'])
                        
                        st.success(f"ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: **{best_model}** "
                                 f"(ì •í™•ë„: {model_results[best_model]['accuracy']*100:.2f}%)")
                        
                        # í”¼ì²˜ ì¤‘ìš”ë„
                        st.subheader("â­ í”¼ì²˜ ì¤‘ìš”ë„")
                        
                        for model_name, result in model_results.items():
                            if result['feature_importance']:
                                st.write(f"**{model_name}**")
                                
                                # ìƒìœ„ 10ê°œ í”¼ì²˜
                                sorted_features = sorted(result['feature_importance'].items(), 
                                                       key=lambda x: x[1], reverse=True)[:10]
                                
                                fig, ax = plt.subplots(figsize=(10, 6))
                                features, importance = zip(*sorted_features)
                                bars = ax.barh(range(len(features)), importance)
                                ax.set_yticks(range(len(features)))
                                ax.set_yticklabels(features)
                                ax.set_xlabel('í”¼ì²˜ ì¤‘ìš”ë„')
                                ax.set_title(f'{model_name} - í”¼ì²˜ ì¤‘ìš”ë„ (ìƒìœ„ 10ê°œ)', 
                                           fontweight='bold')
                                ax.invert_yaxis()
                                
                                st.pyplot(fig)
                    
                    # ì˜ˆì¸¡ ì„¹ì…˜
                    st.subheader("ğŸ”® ìƒˆë¡œìš´ ë°ì´í„° ì˜ˆì¸¡")
                    
                    if model_results:
                        # ëª¨ë¸ ì„ íƒ
                        selected_model = st.selectbox(
                            "ì˜ˆì¸¡ì— ì‚¬ìš©í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”:",
                            list(model_results.keys())
                        )
                        
                        # ì…ë ¥ í¼
                        st.write("ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
                        
                        input_data = {}
                        
                        # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ì…ë ¥
                        for col in stats['numeric_columns']:
                            if col != analyzer.target_col:
                                input_data[col] = st.number_input(
                                    f"{col}",
                                    value=0.0,
                                    step=0.1
                                )
                        
                        # ë²”ì£¼í˜• ë³€ìˆ˜ ì…ë ¥
                        for col in stats['categorical_columns']:
                            if col != analyzer.target_col:
                                input_data[col] = st.text_input(f"{col}")
                        
                        # ì˜ˆì¸¡ ë²„íŠ¼
                        if st.button("ì˜ˆì¸¡í•˜ê¸°"):
                            try:
                                # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
                                df_predict = pd.DataFrame([input_data])
                                
                                # ì „ì²˜ë¦¬
                                for col in stats['categorical_columns']:
                                    if col != analyzer.target_col and col in df_predict.columns:
                                        if col in analyzer.label_encoders:
                                            try:
                                                df_predict[col] = analyzer.label_encoders[col].transform(df_predict[col].astype(str))
                                            except:
                                                df_predict[col] = 0
                                
                                # ì˜ˆì¸¡
                                model = analyzer.models[selected_model]
                                
                                if selected_model == 'XGBoost':
                                    prediction = model.predict(df_predict)[0]
                                    prediction_proba = model.predict_proba(df_predict)[0] if hasattr(model, 'predict_proba') else None
                                else:
                                    df_predict_scaled = analyzer.scaler.transform(df_predict)
                                    prediction = model.predict(df_predict_scaled)[0]
                                    prediction_proba = model.predict_proba(df_predict_scaled)[0] if hasattr(model, 'predict_proba') else None
                                
                                # ê²°ê³¼ í‘œì‹œ
                                st.success(f"ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼: **{prediction}**")
                                
                                if prediction_proba is not None:
                                    st.write("**í´ë˜ìŠ¤ë³„ í™•ë¥ :**")
                                    for i, prob in enumerate(prediction_proba):
                                        st.write(f"í´ë˜ìŠ¤ {i}: {prob*100:.2f}%")
                                
                            except Exception as e:
                                st.error(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                
                else:
                    st.error("ë°ì´í„° ì „ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            else:
                st.error("ë°ì´í„° ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    else:
        # ê¸°ë³¸ í™”ë©´
        st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")
        
        # ì˜ˆì‹œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
        st.subheader("ğŸ“Š ì˜ˆì‹œ ë°ì´í„°")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**í†µì‹ ì‚¬ ê³ ê° ì´íƒˆ ë°ì´í„° (churn.csv)**")
            st.write("- State: ì£¼(State)")
            st.write("- Account_Length: ê³„ì • ê¸°ê°„")
            st.write("- Intl_Plan: êµ­ì œ í”Œëœ ê°€ì… ì—¬ë¶€")
            st.write("- Vmail_Plan: ìŒì„±ë©”ì¼ í”Œëœ ê°€ì… ì—¬ë¶€")
            st.write("- Day_Mins/Eve_Mins/Night_Mins: ì‹œê°„ëŒ€ë³„ í†µí™” ì‹œê°„")
            st.write("- CustServ_Calls: ê³ ê° ì„œë¹„ìŠ¤ í†µí™” íšŸìˆ˜")
            st.write("- Churn: ì´íƒˆ ì—¬ë¶€ (íƒ€ê²Ÿ ë³€ìˆ˜)")
        
        with col2:
            st.write("**í…ŒìŠ¤íŠ¸ ë°ì´í„° (sample_data.csv)**")
            st.write("- age: ë‚˜ì´")
            st.write("- income: ì†Œë“")
            st.write("- education: êµìœ¡ ìˆ˜ì¤€")
            st.write("- city: ë„ì‹œ")
            st.write("- experience: ê²½ë ¥")
            st.write("- satisfaction: ë§Œì¡±ë„")
            st.write("- target: íƒ€ê²Ÿ ë³€ìˆ˜")

if __name__ == "__main__":
    main()
